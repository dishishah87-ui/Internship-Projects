# -*- coding: utf-8 -*-
"""MajorProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hzbPx15vixDXBdlXQWE9-8NlzacpnbOW

# **Import Libraries and Data**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn import metrics
import matplotlib.pyplot as plt
import matplotlib.style
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

from google.colab import files
uploaded=files.upload()

df=pd.read_csv("expected_ctc.csv")

df['Expected_CTC_original']=pd.to_numeric(df['Expected_CTC'], errors='coerce')
df['Expected_CTC_original'].fillna(df['Expected_CTC_original'].median(), inplace=True)

"""# **EDA**

**Head Of Data**
"""

df.head()

"""**Shape Of Data**"""

df.shape

"""**Information Of Data**"""

df.info()

"""**Describe**"""

df.describe(include="all")

"""**Duplicate Checking**"""

dups=df.duplicated()
print("Number Of duplicates:%d"% (dups.sum()))
df[dups]

"""**Check for Outliners**"""

df.boxplot(column="IDX")
plt.show()

df.boxplot(column="Applicant_ID")
plt.show()

df.boxplot(column="Total_Experience")
plt.show()

df.boxplot(column="Total_Experience_in_field_applied")
plt.show()

df.boxplot(column="Passing_Year_Of_Graduation")
plt.show()

df.boxplot(column="Passing_Year_Of_PG")
plt.show()

df.boxplot(column="Passing_Year_Of_PHD")
plt.show()

df.boxplot(column="Current_CTC")
plt.show()

df.boxplot(column="No_Of_Companies_worked")
plt.show()

df.boxplot(column="Number_of_Publications")
plt.show()

df.boxplot(column="Certifications")
plt.show()

df.boxplot(column="International_degree_any")
plt.show()

df.boxplot(column="Expected_CTC")
plt.show()

"""**Treating Outliners**"""

def remove_outliner(col):
  sorted(col)
  Q1,Q3=col.quantile([0.25,0.75])
  IQR=Q3-Q1
  lower_range=Q1-(1.5*IQR)
  upper_range=Q3+(1.5*IQR)
  return lower_range,upper_range

lrTotal_Experience_in_field_applied,urTotal_Experience_in_field_applied=remove_outliner(df["Total_Experience_in_field_applied"])
df["Total_Experience_in_field_applied"]=np.where(df["Total_Experience_in_field_applied"]<lrTotal_Experience_in_field_applied,lrTotal_Experience_in_field_applied,df["Total_Experience_in_field_applied"])
df["Total_Experience_in_field_applied"]=np.where(df["Total_Experience_in_field_applied"]>urTotal_Experience_in_field_applied,urTotal_Experience_in_field_applied,df["Total_Experience_in_field_applied"])

lrCertifications,urCertifications=remove_outliner(df["Certifications"])
df["Certifications"]=np.where(df["Certifications"]<lrCertifications,lrCertifications,df["Certifications"])
df["Certifications"]=np.where(df["Certifications"]>urCertifications,urCertifications,df["Certifications"])

lrInternational_degree_any,urInternational_degree_any=remove_outliner(df["International_degree_any"])
df["International_degree_any"]=np.where(df["International_degree_any"]<lrInternational_degree_any,lrInternational_degree_any,df["International_degree_any"])
df["International_degree_any"]=np.where(df["International_degree_any"]>urInternational_degree_any,urInternational_degree_any,df["International_degree_any"])
df.shape

"""**Rechecking Outliner**"""

df.boxplot(column="IDX")
plt.show()

df.boxplot(column="Applicant_ID")
plt.show()

df.boxplot(column="Total_Experience")
plt.show()

df.boxplot(column="Total_Experience_in_field_applied")
plt.show()

df.boxplot(column="Passing_Year_Of_Graduation")
plt.show()

df.boxplot(column="Passing_Year_Of_PG")
plt.show()

df.boxplot(column="Passing_Year_Of_PHD")
plt.show()

df.boxplot(column="Current_CTC")
plt.show()

df.boxplot(column="No_Of_Companies_worked")
plt.show()

df.boxplot(column="Number_of_Publications")
plt.show()

df.boxplot(column="Certifications")
plt.show()

df.boxplot(column="International_degree_any")
plt.show()

df.boxplot(column="Expected_CTC")
plt.show()

"""**Checking Missing Values**"""

df.isnull().sum()

"""**Replacing Missing Values**"""

df[df.isnull().sum()[df.isnull().sum()>0].index].dtypes

"""**REPLACING NUMERICAL VALUE USING MEDIAN**"""

median1=df["Passing_Year_Of_Graduation"].median()
median2=df["Passing_Year_Of_PG"].median()
median3=df["Passing_Year_Of_PHD"].median()

df["Passing_Year_Of_Graduation"].replace(np.nan,median1,inplace=True)
df["Passing_Year_Of_PG"].replace(np.nan,median2,inplace=True)
df["Passing_Year_Of_PHD"].replace(np.nan,median3,inplace=True)

"""**Replacing Categorical Value using mode**"""

mode1=df["Department"].mode().values[0]
mode2=df["Role"].mode().values[0]
mode3=df["Industry"].mode().values[0]
mode4=df["Organization"].mode().values[0]
mode5=df["Designation"].mode().values[0]
mode6=df["Education"].mode().values[0]
mode7=df["Graduation_Specialization"].mode().values[0]
mode8=df["University_Grad"].mode().values[0]
mode9=df["PG_Specialization"].mode().values[0]
mode10=df["University_PG"].mode().values[0]
mode11=df["PHD_Specialization"].mode().values[0]
mode12=df["University_PHD"].mode().values[0]
mode13=df["Curent_Location"].mode().values[0]
mode14=df["Preferred_location"].mode().values[0]
mode15=df["Inhand_Offer"].mode().values[0]
mode16=df["Last_Appraisal_Rating"].mode().values[0]

df["Department"].replace(np.nan,mode1,inplace=True)
df["Role"].replace(np.nan,mode2,inplace=True)
df["Industry"].replace(np.nan,mode3,inplace=True)
df["Organization"].replace(np.nan,mode4,inplace=True)
df["Designation"].replace(np.nan,mode5,inplace=True)
df["Education"].replace(np.nan,mode6,inplace=True)
df["Graduation_Specialization"].replace(np.nan,mode7,inplace=True)
df["University_Grad"].replace(np.nan,mode8,inplace=True)
df["PG_Specialization"].replace(np.nan,mode9,inplace=True)
df["University_PG"].replace(np.nan,mode10,inplace=True)
df["PHD_Specialization"].replace(np.nan,mode11,inplace=True)
df["University_PHD"].replace(np.nan,mode12,inplace=True)
df["Curent_Location"].replace(np.nan,mode13,inplace=True)
df["Preferred_location"].replace(np.nan,mode14,inplace=True)
df["Inhand_Offer"].replace(np.nan,mode15,inplace=True)
df["Last_Appraisal_Rating"].replace(np.nan,mode16,inplace=True)

"""**Rechecking Missing Values**"""

df.isnull().sum()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df['IDX']=le.fit_transform(df['IDX'])
df['Applicant_ID']=le.fit_transform(df['Applicant_ID'])
df['Total_Experience']=le.fit_transform(df['Total_Experience'])
df['Total_Experience_in_field_applied']=le.fit_transform(df['Total_Experience_in_field_applied'])
df['Department']=le.fit_transform(df['Department'])
df['Role']=le.fit_transform(df['Role'])
df['Industry']=le.fit_transform(df['Industry'])
df['Organization']=le.fit_transform(df['Organization'])
df['Designation']=le.fit_transform(df['Designation'])
df['Education']=le.fit_transform(df['Education'])
df['Graduation_Specialization']=le.fit_transform(df['Graduation_Specialization'])
df['University_Grad']=le.fit_transform(df['University_Grad'])
df['Passing_Year_Of_Graduation']=le.fit_transform(df['Passing_Year_Of_Graduation'])
df['PG_Specialization']=le.fit_transform(df['PG_Specialization'])
df['University_PG']=le.fit_transform(df['University_PG'])
df['Passing_Year_Of_PG']=le.fit_transform(df['Passing_Year_Of_PG'])
df['PHD_Specialization']=le.fit_transform(df['PHD_Specialization'])
df['University_PHD']=le.fit_transform(df['University_PHD'])
df['Passing_Year_Of_PHD']=le.fit_transform(df['Passing_Year_Of_PHD'])
df['Curent_Location']=le.fit_transform(df['Curent_Location'])
df['Preferred_location']=le.fit_transform(df['Preferred_location'])
df['Current_CTC']=le.fit_transform(df['Current_CTC'])
df['Inhand_Offer']=le.fit_transform(df['Inhand_Offer'])
df['Last_Appraisal_Rating']=le.fit_transform(df['Last_Appraisal_Rating'])
df['No_Of_Companies_worked']=le.fit_transform(df['No_Of_Companies_worked'])
df['Number_of_Publications']=le.fit_transform(df['Number_of_Publications'])
df['Certifications']=le.fit_transform(df['Certifications'])
df['International_degree_any']=le.fit_transform(df['International_degree_any'])
df['Expected_CTC']=le.fit_transform(df['Expected_CTC'])
df.head()

"""**Univariate Analysis**"""

sns.histplot(df.IDX,kde=True)

sns.histplot(df.Applicant_ID,kde=True)

sns.histplot(df.Total_Experience,kde=True)

sns.histplot(df.Total_Experience_in_field_applied,kde=True)

sns.histplot(df.Passing_Year_Of_Graduation,kde=True)

sns.histplot(df.Passing_Year_Of_PG,kde=True)

sns.histplot(df.Passing_Year_Of_PHD,kde=True)

sns.histplot(df.Current_CTC,kde=True)

sns.histplot(df.No_Of_Companies_worked,kde=True)

sns.histplot(df.Number_of_Publications,kde=True)

sns.histplot(df.Certifications,kde=True)

sns.histplot(df.International_degree_any,kde=True)

sns.histplot(df.Expected_CTC,kde=True)

"""**Bivariate Analysis**"""

sns.pairplot(df)
plt.show()

df.corr(numeric_only=True)

"""**CORRELATION HEATMAP**"""

plt.figure(figsize=(12,7))
sns.heatmap(df.corr(numeric_only=True),annot=True,fmt=".2f",cmap="Reds")
plt.show()

"""**NORMALIZATION AND STANDARDIZATION**"""

from sklearn.preprocessing import StandardScaler
std_scale=StandardScaler()
std_scale

cols_to_scale=[ "IDX","Applicant_ID","Total_Experience","Total_Experience_in_field_applied",
                "Passing_Year_Of_Graduation","Passing_Year_Of_PG","Passing_Year_Of_PHD",
                "Current_CTC","No_Of_Companies_worked","Number_of_Publications",
                "Certifications","International_degree_any" ]
for col in cols_to_scale:
    df[col]=std_scale.fit_transform(df[[col]])

df.head()

"""**ENCODING**"""

features=['Total_Experience',
            'Total_Experience_in_field_applied',
            'Department',
            'Role',
            'Industry',
            'Organization',
            'Designation',
            'Education',
            'Graduation_Specialization',
            'University_Grad',
            'Passing_Year_Of_Graduation',
            'PG_Specialization',
            'University_PG',
            'Passing_Year_Of_PG',
            'PHD_Specialization',
            'University_PHD',
            'Passing_Year_Of_PHD',
            'Curent_Location',
            'Preferred_location',
            'Current_CTC',
            'Inhand_Offer',
            'Last_Appraisal_Rating',
            'No_Of_Companies_worked',
            'Number_of_Publications',
            'Certifications',
            'International_degree_any']
dv=pd.get_dummies(df[features],drop_first=True)
iv=df["Expected_CTC"].values
X=dv
Y=iv

df.head()

"""# **Random Forest**"""

import warnings
warnings.filterwarnings('ignore')

!rm expected_ctc_model.joblib
!rm scaler.joblib

for column in df.columns:
    plt.figure(figsize=(8,4))
    sns.displot(df[column],bins=20,kde=True)
    plt.title(f"Distribution of {column}")
    plt.show()

x=df.drop('Expected_CTC',axis=1)
y=df['Expected_CTC']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=42)

X = df[['IDX','Applicant_ID','Total_Experience','Total_Experience_in_field_applied',
        'Department','Role','Industry','Organization','Designation','Education',
        'Graduation_Specialization','University_Grad','Passing_Year_Of_Graduation',
        'PG_Specialization','University_PG','Passing_Year_Of_PG','PHD_Specialization',
        'University_PHD','Passing_Year_Of_PHD','Curent_Location','Preferred_location',
        'Current_CTC','Inhand_Offer','Last_Appraisal_Rating','No_Of_Companies_worked',
        'Number_of_Publications','Certifications','International_degree_any']]
y=np.log1p(df['Expected_CTC_original'])
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(X, y, test_size=0.25, random_state=42)

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor
param_grid={'n_estimators':[10,50,100,200],'criterion':['squared_error']}
rf=RandomForestRegressor(random_state=42,n_jobs=-1)
grid_search=GridSearchCV(estimator=rf,param_grid=param_grid,cv=3,n_jobs=-1,verbose=1)
grid_search.fit(x_train,y_train)
print("Best Parameters:",grid_search.best_params_)
print("Best Score:",grid_search.best_score_)

grid_search.best_params_

from sklearn.ensemble import RandomForestRegressor
rf=RandomForestRegressor(n_estimators=100,criterion="squared_error")
rf.fit(x_train,y_train)

y_pred=rf.predict(x_test)
y_pred

rf.score(x_train,y_train)

rf.score(x_test,y_test)

"""# **ROC**"""

from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error
y_pred=rf.predict(x_test)
r2=r2_score(y_test,y_pred)
mae=mean_absolute_error(y_test,y_pred)
rmse=np.sqrt(mean_squared_error(y_test,y_pred))
print("R² Score:",r2)
print("MAE:",mae)
print("RMSE:",rmse)

y_pred=rf.predict(x_test)
plt.figure(figsize=(6,6))
plt.scatter(y_test,y_pred,color='blue',alpha=0.5)
plt.plot([y_test.min(),y_test.max()],[y_test.min(),y_test.max()],color='red',lw=2)
plt.xlabel("Actual Charges")
plt.ylabel("Predicted Charges")
plt.title("Actual vs Predicted Charges (Regression)")
plt.show()

"""**Confusion Matrix**"""

from sklearn.metrics import confusion_matrix
import pandas as pd
bins=[0,10000,20000,100000]
labels=['Low','Medium','High']
y_test_cat=pd.cut(y_test,bins=bins,labels=labels,include_lowest=True)
y_pred_cat=pd.cut(y_pred,bins=bins,labels=labels,include_lowest=True)
y_test_cat=y_test_cat.astype(str)
y_pred_cat=y_pred_cat.astype(str)
cm=confusion_matrix(y_test_cat,y_pred_cat,labels=labels)
print("Confusion Matrix:\n",cm)

sns.heatmap(cm,annot=True,fmt="d")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

from sklearn.metrics import classification_report
import pandas as pd
bins=[0,10000,20000,100000]
labels=['Low','Medium','High']
y_test_cat=pd.cut(y_test,bins=bins,labels=labels,include_lowest=True)
y_pred_cat=pd.cut(y_pred,bins=bins,labels=labels,include_lowest=True)
y_test_cat=y_test_cat.astype(str)
y_pred_cat=y_pred_cat.astype(str)
cr=classification_report(y_test_cat,y_pred_cat,labels=labels)
print(cr)

"""# **Final Prediction**

**1.List Of Departments:HR,Top
Management,Banking,Sales,Engineering,Others,Analytics/BI,Education,Marketing,Healthcare,IT-Software,Accounts**

**2.List Of Role:Consultant,Financial Analyst,Project Manager,Area Sales Manager,Team Lead,Analyst,Others,CEO,Business Analyst,Sales Manager,
Bio statistician,Scientist,Research Scientist,Head,Associate,Senior Researcher,Sales Execituve,Sr. Business Analyst,Principal Analyst,
Data scientist,Researcher,Senior Analyst,Professor,Lab Executuve**

**3.List of Industry:NA,Analytics,Training,Aviation,Insurance,Retail,FMCG,Others,Telecom,Automobile,IT,BFSI**

**4.List of Organisation:A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P**

**5.List of Designation:HR,Medical Officer,Director,Marketing Manager,Manager,Product Manager,Consultant,CA,Research Scientist,Sr.Manager,Data Analyst,Assistant Manager,Others,Web Designer,Research Analyst,Software Developer,Network Engineer,Scientist**

**6.List of Education:PG,Doctorate,Grad,Under Grad**

**7.List of Graduation Specialization:Arts,Chemistry,Zoology,Others,Sociology,Psychology,Mathematics,Engineering,Botony,Statistics,Economics**

**8.Place of University_Grad:Lucknow,Surat,Jaipur,Bangalore,Mumbai,Delhi,Mangalore,Nagpur,Kolkata,Ahemdabad,Guwahati,Pune,Bhubaneswar**

**9.Place of PG Specialization:Others,Zoology,Chemistry,Psychology,Mathematics,Engineering,Sociology,Arts,Statistics,Economics,Botony**

**10.Place of University PG:Lucknow,Surat,Jaipur,Bangalore,Mumbai,Delhi,Mangalore,Nagpur,Kolkata,Ahemdabad,Guwahati,Pune,Bhubaneswar**

**11.PHD Specialization:Others,Zoology,Chemistry,Psychology,Mathematics,Engineering,Sociology,Arts,Statistics,Economics,Botony**

**12.Place of PHD University:Lucknow,Surat,Jaipur,Bangalore,Mumbai,Delhi,Mangalore,Nagpur,Kolkata,Ahemdabad,Guwahati,Pune,Bhubaneswar**

**13.List Of Current Locations:Guwahati,Bangalore,Ahmedabad,Kanpur,Pune,Delhi,Surat,Nagpur,Jaipur,Kolkata,Bhubaneswar,Mangalore,Mumbai,Lucknow,Chennai**

**14.List of Preferred Locations:Guwahati,Bangalore,Ahmedabad,Kanpur,Pune,Delhi,Surat,Nagpur,Jaipur,Kolkata,Bhubaneswar,Mangalore,Mumbai,Lucknow,Chennai**
"""

from joblib import load, dump
import numpy as np, os
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
if not (os.path.exists("expected_ctc_model.joblib") and os.path.exists("scaler.joblib")):
    print("Model or scaler not found — training a new one...")
    X = df[['IDX','Applicant_ID','Total_Experience','Total_Experience_in_field_applied','Department','Role','Industry','Organization',
            'Designation','Education','Graduation_Specialization','University_Grad','Passing_Year_Of_Graduation','PG_Specialization',
            'University_PG','Passing_Year_Of_PG','PHD_Specialization','University_PHD','Passing_Year_Of_PHD','Curent_Location',
            'Preferred_location','Current_CTC','Inhand_Offer','Last_Appraisal_Rating','No_Of_Companies_worked',
            'Number_of_Publications','Certifications','International_degree_any']]
    y = np.log1p(df['Expected_CTC_original'])
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    rf = RandomForestRegressor(n_estimators=100, random_state=42)
    rf.fit(X_scaled, y)
    dump(rf, "expected_ctc_model.joblib")
    dump(scaler, "scaler.joblib")
    print("Model and scaler saved successfully!")
rf = load("expected_ctc_model.joblib")
scaler = load("scaler.joblib")
!rm expected_ctc_model.joblib
!rm scaler.joblib
print("\nEnter candidate details for Expected CTC prediction:\n")
IDX=int(input("Enter IDX: "))
Applicant_ID=int(input("Enter Applicant_ID: "))
Total_Experience=float(input("Enter Total_Experience (in years): "))
Total_Experience_in_field_applied=float(input("Enter Total_Experience_in_field_applied (in years): "))
Department=input("Enter Department: ").strip()
role=input("Enter Role: ").strip()
Industry=input("Enter Industry: ").strip()
Organization=input("Enter Organization: ").strip()
Designation=input("Enter Designation: ").strip()
Education=input("Enter Education: ").strip()
Graduation_Specialization=input("Enter Graduation Specialization: ").strip()
University_Grad=input("Enter University (Graduation): ").strip()
Passing_Year_Of_Graduation=int(input("Enter Passing Year Of Graduation: "))
PG_Specialization=input("Enter PG Specialization: ").strip()
University_PG=input("Enter University (PG): ").strip()
Passing_Year_Of_PG=int(input("Enter Passing Year Of PG: "))
PHD_Specialization=input("Enter PHD Specialization: ").strip()
University_PHD=input("Enter University (PHD): ").strip()
Passing_Year_Of_PHD=int(input("Enter Passing Year Of PHD: "))
Curent_Location=input("Enter Current Location: ").strip()
Preferred_location=input("Enter Preferred Location: ").strip()
Current_CTC=float(input("Enter Current CTC: "))
Inhand_Offer=input("Do you have an in-hand offer? (yes/no): ").strip().lower()
Inhand_Offer=1 if Inhand_Offer=='yes' else 0
Last_Appraisal_Rating=input("Enter Last Appraisal Rating (A/B/C/D/Key Performer): ").strip()
No_Of_Companies_worked=int(input("Enter No Of Companies worked (0–6): "))
Number_of_Publications=int(input("Enter Number of Publications (0–7): "))
Certifications=int(input("Enter Number of Certifications (0/1): "))
International_degree_any=input("Any International degree? (yes/no): ").strip().lower()
International_degree_any=1 if International_degree_any=='yes' else 0
Department_mapping={'HR':0,'Top Management':1,'Banking':2,'Sales':3,'Engineering':4,'Others':5,'Analytics/BI':6,'Education':7,'Marketing':8,
                    'Healthcare':9,'IT-Software':10,'Accounts':11}
role_mapping={'Consultant':0,'Financial Analyst':1,'Project Manager':2,'Area Sales Manager':3,'Team Lead':4,'Analyst':5,'Others':6,'CEO':7,
              'Business Analyst':8,'Sales Manager':9,'Bio statistician':10,'Scientist':11,'Research Scientist':12,'Head':13,'Associate':14,
              'Senior Researcher':15,'Sales Execituve':16,'Sr. Business Analyst':17,'Principal Analyst':18,'Data scientist':19,'Researcher':20,
              'Senior Analyst':21,'Professor':22,'Lab Executuve':23}
Industry_mapping={'NA':0,'Analytics':1,'Training':2,'Aviation':3,'Insurance':4,'Retail':5,'FMCG':6,'Others':7,'Telecom':8,'Automobile':9,'IT':10,'BFSI':11}
Organization_mapping={'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,'N':13,'O':14,'P':15}
Designation_mapping={'HR':0,'Medical Officer':1,'Director':2,'Marketing Manager':3,'Manager':4,'Product Manager':5,'Consultant':6,'CA':7,
                     'Research Scientist':8,'Sr.Manager':9,'Data Analyst':10,'Assistant Manager':11,'Others':12,'Web Designer':13,
                     'Research Analyst':14,'Software Developer':15,'Network Engineer':16,'Scientist':17}
Education_mapping={'PG':0,'Doctorate':1,'Grad':2,'Under Grad':3}
Graduation_Specialization_mapping={'Arts':0,'Chemistry':1,'Zoology':2,'Others':3,'Sociology':4,'Psychology':5,'Mathematics':6,'Engineering':7,
                                   'Botony':8,'Statistics':9,'Economics':10}
University_Grad_mapping={'Lucknow':0,'Surat':1,'Jaipur':2,'Bangalore':3,'Mumbai':4,'Delhi':5,'Mangalore':6,'Nagpur':7,'Kolkata':8,'Ahemdabad':9,
                         'Guwahati':10,'Pune':11,'Bhubaneswar':12}
PG_Specialization_mapping=Graduation_Specialization_mapping
University_PG_mapping=University_Grad_mapping
PHD_Specialization_mapping=Graduation_Specialization_mapping
University_PHD_mapping=University_Grad_mapping
Curent_Location_mapping={'Guwahati':0,'Bangalore':1,'Ahmedabad':2,'Kanpur':3,'Pune':4,'Delhi':5,'Surat':6,'Nagpur':7,'Jaipur':8,'Kolkata':9,
                         'Bhubaneswar':10,'Mangalore':11,'Mumbai':12,'Lucknow':13,'Chennai':14}
Preferred_location_mapping=Curent_Location_mapping
Last_Appraisal_Rating_mapping={'A':0,'B':1,'C':2,'D':3,'Key Performer':4}
Department_val=Department_mapping.get(Department,5)
role_val=role_mapping.get(role,6)
Industry_val=Industry_mapping.get(Industry,7)
Organization_val=Organization_mapping.get(Organization,15)
Designation_val=Designation_mapping.get(Designation,12)
Education_val=Education_mapping.get(Education,2)
Graduation_Specialization_val=Graduation_Specialization_mapping.get(Graduation_Specialization,3)
University_Grad_val=University_Grad_mapping.get(University_Grad,12)
PG_Specialization_val=PG_Specialization_mapping.get(PG_Specialization,3)
University_PG_val=University_PG_mapping.get(University_PG,12)
PHD_Specialization_val=PHD_Specialization_mapping.get(PHD_Specialization,3)
University_PHD_val=University_PHD_mapping.get(University_PHD,12)
Curent_Location_val=Curent_Location_mapping.get(Curent_Location,13)
Preferred_location_val=Preferred_location_mapping.get(Preferred_location,13)
Last_Appraisal_Rating_val=Last_Appraisal_Rating_mapping.get(Last_Appraisal_Rating,1)
features=np.array([IDX, Applicant_ID, Total_Experience, Total_Experience_in_field_applied,Department_val, role_val, Industry_val,
                   Organization_val,Designation_val, Education_val, Graduation_Specialization_val,University_Grad_val,
                   Passing_Year_Of_Graduation, PG_Specialization_val,University_PG_val, Passing_Year_Of_PG, PHD_Specialization_val,
                   University_PHD_val, Passing_Year_Of_PHD, Curent_Location_val,Preferred_location_val, Current_CTC, Inhand_Offer,
                  Last_Appraisal_Rating_val, No_Of_Companies_worked,Number_of_Publications, Certifications, International_degree_any]).reshape(1,-1)
expected_features = rf.n_features_in_
X_scaled = scaler.transform(features)
predicted_log = rf.predict(X_scaled)
predicted_rupees = np.expm1(predicted_log)[0]
print(f"\nPredicted Expected CTC: ₹{predicted_rupees:,.3f} per annum")

print("Training Accuracy:", rf.score(x_train, y_train))
print("Testing Accuracy:", rf.score(x_test, y_test))