# -*- coding: utf-8 -*-
"""LDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10Tui84uD-foEfMwCS31BYSaCKMzuQfBi

#**Libraries And Data**
"""

import pandas as pd
import numpy as np
import os
import scipy.stats as stats
import matplotlib.pyplot as plt
plt.rc("font",size=14)
import seaborn as sns
sns.set(style="white")
sns.set(style="whitegrid",color_codes=True)
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import scale

from google.colab import files
uploaded = files.upload()

df=pd.read_csv("data.csv")

df.drop(columns=['Unnamed: 32'], inplace=True, errors='ignore')
for col in df.columns:
    if df[col].dtype == 'object':
        df[col].fillna(df[col].mode()[0], inplace=True)
    else:
        df[col].fillna(df[col].mean(), inplace=True)

"""# **EDA**"""

df.head(10)

df.tail(20)

df.describe()

df.dtypes

type(df)

df.isnull().sum()

df.shape

df['diagnosis'] = df['diagnosis'].astype('object')

df['id'].unique()

df['diagnosis'].unique()

df['radius_mean'].unique()

df['texture_mean'].unique()

df['perimeter_mean'].unique()

df['area_mean'].unique()

df['smoothness_mean'].unique()

df['compactness_mean'].unique()

df['concavity_mean'].unique()

df['concave points_mean'].unique()

df['symmetry_mean'].unique()

df['fractal_dimension_mean'].unique()

df['radius_se'].unique()

df['texture_se'].unique()

df['perimeter_se'].unique()

df['area_se'].unique()

df['smoothness_se'].unique()

df['compactness_se'].unique()

df['concavity_se'].unique()

df['concave points_se'].unique()

df['symmetry_se'].unique()

df['fractal_dimension_se'].unique()

df['radius_worst'].unique()

df['texture_worst'].unique()

df['perimeter_worst'].unique()

df['area_worst'].unique()

df['smoothness_worst'].unique()

df['compactness_worst'].unique()

df['concavity_worst'].unique()

df['concave points_worst'].unique()

df['symmetry_worst'].unique()

df['fractal_dimension_worst'].unique()

df['diagnosis'].value_counts()

if 'id' in df.columns:
    df = df.drop('id', axis=1)

if df.isnull().sum().sum() > 0:
    print("⚠️ Still contains NaN values:")
    print(df.isnull().sum()[df.isnull().sum() > 0])
    raise ValueError("❌ Clean your dataset: still contains NaN.")
else:
    print("✅ No NaN values remain!")

"""# **Univariate Plots**"""

sns.displot(df['radius_mean'])

sns.displot(df['texture_mean'])

sns.displot(df['perimeter_mean'])

sns.displot(df['area_mean'])

sns.displot(df['smoothness_mean'])

sns.displot(df['compactness_mean'])

sns.displot(df['concavity_mean'])

sns.displot(df['concave points_mean'])

sns.displot(df['symmetry_mean'])

sns.displot(df['fractal_dimension_mean'])

sns.displot(df['radius_se'])

sns.displot(df['texture_se'])

sns.displot(df['perimeter_se'])

sns.displot(df['area_se'])

sns.displot(df['smoothness_se'])

sns.displot(df['compactness_se'])

sns.displot(df['concavity_se'])

sns.displot(df['concave points_se'])

sns.displot(df['symmetry_se'])

sns.displot(df['fractal_dimension_se'])

sns.displot(df['radius_worst'])

sns.displot(df['texture_worst'])

sns.displot(df['perimeter_worst'])

sns.displot(df['area_worst'])

sns.displot(df['smoothness_worst'])

sns.displot(df['compactness_worst'])

sns.displot(df['concavity_worst'])

sns.displot(df['concave points_worst'])

sns.displot(df['symmetry_worst'])

sns.displot(df['fractal_dimension_worst'])

"""# **Bivariate Analysis**"""

selected_features = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'diagnosis']
sns.pairplot(df[selected_features], hue='diagnosis', diag_kind='kde', palette='Set1')
plt.suptitle("Pairplot of Selected Features (Bivariate Analysis)", y=1.02, fontsize=16)
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""# **LDA Model**"""

y = df['diagnosis'].map({'M': 1, 'B': 0})
X = df.drop('diagnosis', axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

lda_model = LDA()
lda_model.fit(X_train_scaled, y_train)
y_pred = lda_model.predict(X_test_scaled)

X_test_lda = lda_model.transform(X_test_scaled)
sns.scatterplot(x=X_test_lda[:, 0], y=[0]*len(X_test_lda), hue=y_pred, palette='coolwarm')